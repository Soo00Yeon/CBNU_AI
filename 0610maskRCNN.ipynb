{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발견된 수술 도구 카테고리: 26개\n",
      " ID 1: Bowel Graspers (straight) (AESCULAP) (GRSL-BWAE)\n",
      " ID 2: Dissector (Artisential) (DSTL-ATUK)\n",
      " ID 3: Dissector (kelly) (AESCULAP) (DSTL-KLAE)\n",
      " ID 4: Drain (JPCL-UCUK)\n",
      " ID 5: Endobulldog Clamp (CLML-BDUK)\n",
      " ID 6: Gauze (GAUL-UCUK)\n",
      " ID 7: Gauze Ball (GAUL-BAUK)\n",
      " ID 8: Graspers (curved) (KARL STORZ) (GRSL-C2KS)\n",
      " ID 9: Graspers (curved) (KARL STORZ) (GRSL-CIKS)\n",
      " ID 10: Graspers (duckbill) (GRSL-DBUK)\n",
      " ID 11: Graspers (straight) (KARL STORZ) (GRSL-STKS)\n",
      " ID 12: Harmonic Scalpel (ETHICON) (HMSL-UCET)\n",
      " ID 13: Irrigator (IRGL-UCUK)\n",
      " ID 14: Ligasure (COVIDIEN) (LGSL-MACV)\n",
      " ID 15: Linear Stapler (EGSL-UCUK)\n",
      " ID 16: Linear Stapler (ETHICON) (STPL-UCET)\n",
      " ID 17: Liver retractor (LVRL-UCUK)\n",
      " ID 18: Needle Holder (AESCULAP) (NDHL-UCAE)\n",
      " ID 19: Obturator (OBTL-UCUK)\n",
      " ID 20: Polymer Clip Applier (CLAL-UCUK)\n",
      " ID 21: Spatula Suction (ETHICON) (SPSL-UCET)\n",
      " ID 22: Specimen Retrieval Bag (RTBL-UCUK)\n",
      " ID 23: Suction Irrigator (ETHICON) (SIRL-UCET)\n",
      " ID 24: Suction Irrigator (RDSL-UCUK)\n",
      " ID 25: Suction Irrigator (SIRL-UCUK)\n",
      " ID 26: Trocar (TRCL-UCUK)\n",
      "발견된 수술 단계: 13개 - ['Anastomosis', 'Closure', 'Duodenal transection', 'Left greater curvature dissection', 'Lesser curvature preparation', 'Preparation', 'Proximal stomach transection', 'Right greater curvature dissection', 'Right lesser curvature dissection', 'Right paracardial dissection', 'Stomach specimen removal', 'Suprapancreatic dissection', 'Unknown']\n",
      "데이터셋 준비 시작 :  하위 폴더에서 모든 xmL 파일을 찾습니다.\n",
      "총 31086개의 XML 파일을 찾았습니다.\n",
      "진행 중 : 31086 / 31086 항목 처리 완료\n",
      "==================================================\n",
      "총 9767개 학습/검증용 아이템 준비 완료\n",
      "==================================================\n",
      "'train' 데이터셋에 8790개 이미지를 로드했습니다.\n",
      "'val' 데이터셋에 977개 이미지를 로드했습니다.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                13\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           surgical_tool_phase\n",
      "NUM_CLASSES                    27\n",
      "NUM_PHASES                     13\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                4395\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               488\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "\n",
      "--- 1단계: Mask R-CNN (특징 추출기) 학습 시작 ---\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-2aa7c4a4dd9d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;31m# --- 1단계: Mask R-CNN 학습 ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# 이미 학습된 가중치가 있다면 이 단계를 건너뛸 수 있습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mmrcnn_weights_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_mask_rcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOCO_MODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0;31m# mrcnn_weights_path = \"/path/to/your/trained/weights.h5\" # 직접 경로 지정도 가능\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-2aa7c4a4dd9d>\u001b[0m in \u001b[0;36mtrain_mask_rcnn\u001b[0;34m(config, train_dataset, val_dataset, model_dir, coco_model_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# 전이 학습을 위해 COCO 가중치 로드 (최종 레이어 제외)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     model.load_weights(coco_model_path, by_name=True, exclude=[\n\u001b[0;32m---> 19\u001b[0;31m         \"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"헤드 레이어 학습...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, exclude)\u001b[0m\n\u001b[1;32m   2124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m         \u001b[0;31m# Update the log directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2126\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_log_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_imagenet_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\u001b[0m in \u001b[0;36mset_log_dir\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m   2243\u001b[0m             \u001b[0;31m# /path/to/logs/coco20171029T2315/mask_rcnn_coco_0001.h5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m             \u001b[0mregex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\".*/[\\w-]+(\\d{4})(\\d{2})(\\d{2})T(\\d{2})(\\d{2})/mask\\_rcnn\\_[\\w-]+(\\d{4})\\.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 now = datetime.datetime(int(m.group(1)), int(m.group(2)), int(m.group(3)),\n",
      "\u001b[0;32m/usr/lib/python3.6/re.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \"\"\"Try to apply the pattern at the start of the string, returning\n\u001b[1;32m    171\u001b[0m     a match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfullmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Keras/TF 버전으로 수정: 필요한 라이브러리 임포트\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Keras 및 TensorFlow 관련 라이브러리\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# lxml 임포트\n",
    "try:\n",
    "    import lxml.etree as etree\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as etree\n",
    "    print(\"경고: lxml 라이브러리를 찾을 수 없어 표준 xml.etree.ElementTree를 사용합니다.\")\n",
    "\n",
    "# Matterport Mask R-CNN 라이브러리 임포트\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "\n",
    "# --- 1. 데이터 파싱 및 설정 클래스 (이전과 거의 동일) ---\n",
    "# 이전 답변에서 제공된 SurgicalDatasetParser, SurgicalDataset, SurgicalConfig 클래스를 그대로 사용합니다.\n",
    "# 생략된 코드는 첨부된 파일 [1] 또는 이전 답변을 참고해주세요.\n",
    "class SurgicalDatasetParser:\n",
    "    # ... 이전 코드와 동일 ... [1]\n",
    "    def __init__(self, base_path, phase_directory_path):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.label_path = self.base_path/\"라벨링데이터\"/\"클래스1.(수술도구 이미지)\"/\"01.원위부위절제술\"\n",
    "        self.image_path = self.base_path/\"원천데이터\"/\"클래스1.(수술도구 이미지)\"/\"01.원위부위절제술\"\n",
    "        self.tool_categories = self._discover_tool_categories()\n",
    "        self.class_to_idx = {cat['name']: cat['id'] for cat in self.tool_categories}\n",
    "        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}\n",
    "        print(f\"발견된 수술 도구 카테고리: {len(self.tool_categories)}개\")\n",
    "        for cat in self.tool_categories: print(f\" ID {cat['id']}: {cat['name']}\")\n",
    "        self.image_stem_to_phase_map = self._load_phase_data(phase_directory_path)\n",
    "        if self.image_stem_to_phase_map:\n",
    "            self.phases = sorted(list(set(self.image_stem_to_phase_map.values())))\n",
    "            self.phase_to_idx = {name: i for i, name in enumerate(self.phases)}\n",
    "            self.idx_to_phase = {i: name for i, name in enumerate(self.phases)}\n",
    "            self.num_phases = len(self.phases)\n",
    "            print(f\"발견된 수술 단계: {self.num_phases}개 - {self.phases}\")\n",
    "        else:\n",
    "            self.phases, self.phase_to_idx, self.idx_to_phase, self.num_phases = [], {}, {}, 0\n",
    "    def _discover_tool_categories(self):\n",
    "        categories = []\n",
    "        if self.label_path.exists():\n",
    "            tool_folders = sorted([f for f in self.label_path.iterdir() if f.is_dir()])\n",
    "            categories = [{\"id\": idx + 1, \"name\": folder.name} for idx, folder in enumerate(tool_folders)]\n",
    "        return categories\n",
    "    def _load_phase_data(self, phase_directory_path):\n",
    "        image_stem_to_phase = {}\n",
    "        if not phase_directory_path: return image_stem_to_phase\n",
    "        phase_dir = Path(phase_directory_path)\n",
    "        if not phase_dir.is_dir(): return image_stem_to_phase\n",
    "        for json_file_path in phase_dir.glob(\"*.json\"):\n",
    "            try:\n",
    "                with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                for entry in data:\n",
    "                    if isinstance(entry, dict) and \"filename\" in entry and \"phase\" in entry:\n",
    "                        image_stem_to_phase[Path(entry[\"filename\"]).stem] = entry[\"phase\"]\n",
    "            except Exception: continue\n",
    "        return image_stem_to_phase\n",
    "    def prepare_dataset_for_keras(self):\n",
    "                                               \n",
    "        print(\"데이터셋 준비 시작 :  하위 폴더에서 모든 xmL 파일을 찾습니다.\")\n",
    "        all_xml_files = list(self.label_path.rglob(\"*.xml\"))\n",
    "        total_items = len(all_xml_files)\n",
    "                                               \n",
    "        if total_items == 0:\n",
    "            print(\"경고 : 지정된 경로에서 XML 파일을 찾을 수 없습니다.\")\n",
    "            return \n",
    "                                               \n",
    "        print(f\"총 {total_items}개의 XML 파일을 찾았습니다.\")   \n",
    "                                               \n",
    "        processed_count = 0\n",
    "\n",
    "        for i, xml_file in enumerate(all_xml_files):\n",
    "            print(f\"진행 중 : {i + 1} / {total_items} 항목 처리 완료\", end = '\\r') \n",
    "            tool_dir_name = xml_file.parent.name\n",
    "\n",
    "            annotation = self._parse_xml_annotation(xml_file)\n",
    "            if not annotation or not annotation.get('objects'): continue\n",
    "\n",
    "            image_file = self._find_matching_image(xml_file.stem, tool_dir_name)\n",
    "\n",
    "            if not image_file: continue\n",
    "\n",
    "            phase_label = self.image_stem_to_phase_map.get(xml_file.stem)\n",
    "            if phase_label is None or phase_label not in self.phase_to_idx: continue\n",
    "            processed_count += 1\n",
    "                                               \n",
    "            yield{\n",
    "                'image_path': str(image_file),\n",
    "                'width': annotation['size']['width'], \n",
    "                'height': annotation['size']['height'],\n",
    "                'objects': annotation['objects'],\n",
    "                'phase_id': self.phase_to_idx[phase_label]\n",
    "            }\n",
    "                                               \n",
    "        print(\"\\n\" + \"=\"*50)                                               \n",
    "        print(f\"총 {processed_count}개 학습/검증용 아이템 준비 완료\")\n",
    "        print(\"=\"*50)       \n",
    "                                               \n",
    "        #return dataset_items\n",
    "                                               \n",
    "    def _parse_xml_annotation(self, xml_file):\n",
    "        try:\n",
    "            tree = etree.parse(str(xml_file))\n",
    "            root = tree.getroot()\n",
    "                                               \n",
    "            size_elem = root.find('size')\n",
    "            if size_elem is None or size_elem.find('width') is None or size_elem.find('height') is None:\n",
    "                return None    \n",
    "            width = int(size_elem.find('width').text)\n",
    "            height = int(size_elem.find('height').text)\n",
    "            objects = []\n",
    "                                               \n",
    "            for obj_elem in tree.findall('object'):\n",
    "                class_name_elem = obj_elem.find('name')\n",
    "                if class_name_elem is None or class_name_elem.text not in self.class_to_idx: continue\n",
    "\n",
    "                class_name = class_name_elem.text                               \n",
    "                points_elem = obj_elem.find('points')\n",
    "                if points_elem is not None:\n",
    "                    x_coords = points_elem.findall('x')\n",
    "                    y_coords = points_elem.findall('y')\n",
    "                    points = [{'x': float(x.text), 'y': float(y.text)} for x, y in zip(x_coords,y_coords)]\n",
    "                    if points: objects.append({'name': class_name, 'points': points})\n",
    "            return {'size': {'width': width, 'height': height}, 'objects': objects}\n",
    "                                               \n",
    "        except etree.XMLSyntaxError as e: \n",
    "            print(f\"\\n [오류]XML 파일 파싱 오류 {xml_file.name}:{e} 이 파일을 건너 뜁니다. \")                        \n",
    "            return None\n",
    "                                               \n",
    "        except Exception  as e: \n",
    "            print(f\"\\n [오류]알 수 없는 오류 발생 {xml_file.name}:{e} 이 파일을 건너 뜁니다. \")                        \n",
    "            return None\n",
    "                                               \n",
    "    def _find_matching_image(self, stem, folder):\n",
    "        image_tool_folder = self.image_path / folder           \n",
    "        if not image_tool_folder.is_dir():\n",
    "            return None\n",
    "        possible_extensions = ['.png', '.jpg','.jpeg','.PNG', '.JPG','.JPEG'] \n",
    "        try:\n",
    "                                               \n",
    "            for ext in possible_extensions:\n",
    "                img_path = self.image_path / folder / (stem + ext)\n",
    "                if img_path.exists():\n",
    "                    return img_path\n",
    "        except Exception as e:\n",
    "            print(f\"[경고] 디렉토리 접근 오류. 건너뜁니다. 경로: {image_tool_folder} / {stem}(오류 : {e})\")\n",
    "            return None\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurgicalDataset(utils.Dataset):\n",
    "    # ... 이전 코드와 동일 ... [1]\n",
    "    def load_surgical_data(self, parser, dataset_items, dataset_type):\n",
    "        self.parser = parser\n",
    "        for cat in self.parser.tool_categories: self.add_class(\"surgical_tool\", cat['id'], cat['name'])\n",
    "        for i, item in enumerate(dataset_items):\n",
    "            self.add_image(\"surgical_tool\", image_id=i, path=item['image_path'], width=item['width'], height=item['height'], polygons=item['objects'], phase_id=item['phase_id'])\n",
    "        print(f\"'{dataset_type}' 데이터셋에 {len(dataset_items)}개 이미지를 로드했습니다.\")\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        masks, class_ids = [], []\n",
    "        for obj in info[\"polygons\"]:\n",
    "            points = np.array([[p['x'], p['y']] for p in obj['points']], dtype=np.int32)\n",
    "            mask = np.zeros([info[\"height\"], info[\"width\"]], dtype=np.uint8)\n",
    "            cv2.fillPoly(mask, [points], 1)\n",
    "            masks.append(mask)\n",
    "            class_ids.append(self.parser.class_to_idx[obj['name']])\n",
    "        return (np.stack(masks, axis=-1).astype(bool), np.array(class_ids, dtype=np.int32)) if masks else super(self.__class__, self).load_mask(image_id)\n",
    "    def image_reference(self, image_id): return self.image_info[image_id][\"path\"]\n",
    "    def load_phase_label(self, image_id): return self.image_info[image_id]['phase_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SurgicalConfig(Config):\n",
    "    # ... 이전 코드와 동일 ... [1]\n",
    "    NAME = \"surgical_tool_phase\"\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 2\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    LEARNING_RATE = 0.001\n",
    "\n",
    "# --- 2. 모델 학습 및 특징 추출, 분류기 학습 함수 정의 ---\n",
    "\n",
    "def train_mask_rcnn(config, train_dataset, val_dataset, model_dir, coco_model_path):\n",
    "    \"\"\"1단계: Mask R-CNN 모델을 학습시킵니다.\"\"\"\n",
    "    print(\"\\n--- 1단계: Mask R-CNN (특징 추출기) 학습 시작 ---\")\n",
    "    model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=model_dir)\n",
    "    \n",
    "    # 전이 학습을 위해 COCO 가중치 로드 (최종 레이어 제외)\n",
    "    model.load_weights(coco_model_path, by_name=True, exclude=[\n",
    "        \"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "    print(\"헤드 레이어 학습...\")\n",
    "    model.train(train_dataset, val_dataset,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=5, # 예시: 실제로는 더 많은 에폭 필요\n",
    "                layers='heads')\n",
    "    \n",
    "    print(\"모든 레이어 미세 조정 학습...\")\n",
    "    model.train(train_dataset, val_dataset,\n",
    "                learning_rate=config.LEARNING_RATE / 10,\n",
    "                epochs=10, # 예시: 실제로는 더 많은 에폭 필요\n",
    "                layers='all')\n",
    "    \n",
    "    print(\"Mask R-CNN 학습 완료.\")\n",
    "    return model.find_last() # 학습된 최신 가중치 경로 반환\n",
    "\n",
    "def extract_features(inference_config, dataset, model_path):\n",
    "    \"\"\"학습된 Mask R-CNN을 사용하여 특징 벡터를 추출합니다.\"\"\"\n",
    "    print(\"\\n--- 2단계 (준비): 이미지 특징 벡터 추출 시작 ---\")\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", config=inference_config, model_dir=os.path.dirname(model_path))\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "\n",
    "    # ResNet 백본의 마지막 출력을 특징으로 사용하기 위한 새로운 모델 정의\n",
    "    # 'res5c_out'은 ResNet-101의 마지막 컨볼루션 블록의 출력 레이어 이름입니다.\n",
    "    feature_extractor = Model(inputs=model.keras_model.input,\n",
    "                              outputs=model.keras_model.get_layer('res5c_out').output)\n",
    "    \n",
    "    features = []\n",
    "    phase_labels = []\n",
    "    \n",
    "    for image_id in dataset.image_ids:\n",
    "        image = dataset.load_image(image_id)\n",
    "        # 이미지를 모델 입력에 맞게 리사이즈 및 정규화\n",
    "        molded_image, _, _, _, _ = utils.mold_inputs([image], inference_config)\n",
    "        # 특징 추출\n",
    "        feature_map = feature_extractor.predict(molded_image)\n",
    "        # 특징 맵을 1D 벡터로 변환 (Global Average Pooling)\n",
    "        vector = np.mean(feature_map, axis=(1, 2)).squeeze()\n",
    "        \n",
    "        features.append(vector)\n",
    "        phase_labels.append(dataset.load_phase_label(image_id))\n",
    "        \n",
    "        if (image_id + 1) % 100 == 0:\n",
    "            print(f\"{image_id + 1} / {len(dataset.image_ids)} 이미지 처리 완료\")\n",
    "\n",
    "    print(f\"총 {len(features)}개의 특징 벡터 추출 완료.\")\n",
    "    return np.array(features), np.array(phase_labels)\n",
    "\n",
    "def train_phase_classifier(X_train, y_train, X_val, y_val, num_phases, model_save_path):\n",
    "    #\"\"\"추출된 특징 벡터로 수술 단계 분류기를 학습합니다.\"\"\"\n",
    "    print(\"\\n--- 2단계: 수술 단계 분류기 학습 시작 ---\")\n",
    "    \n",
    "    # 라벨을 원-핫 인코딩으로 변환\n",
    "    y_train_cat = to_categorical(y_train, num_classes=num_phases)\n",
    "    y_val_cat = to_categorical(y_val, num_classes=num_phases)\n",
    "    \n",
    "    input_shape = (X_train.shape[1],)\n",
    "    \n",
    "    # 간단한 MLP 모델 정의\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    x = Dense(512, activation='relu')(input_tensor)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_tensor = Dense(num_phases, activation='softmax')(x)\n",
    "    \n",
    "    classifier = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    \n",
    "    classifier.compile(optimizer=Adam(lr=0.0001),\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "    \n",
    "    print(classifier.summary())\n",
    "    \n",
    "    classifier.fit(X_train, y_train_cat,\n",
    "                   validation_data=(X_val, y_val_cat),\n",
    "                   epochs=30, # 예시: 실제로는 더 많은 에폭 필요\n",
    "                   batch_size=32)\n",
    "    \n",
    "    classifier.save(model_save_path)\n",
    "    print(f\"단계 분류기 모델 저장 완료: {model_save_path}\")\n",
    "    return classifier\n",
    "\n",
    "# --- 3. 통합 추론 파이프라인 클래스 ---\n",
    "\n",
    "class SurgicalPipeline:\n",
    "    \"\"\"Mask R-CNN과 단계 분류기를 통합하여 추론을 수행하는 클래스\"\"\"\n",
    "    def __init__(self, mrcnn_config, mrcnn_weights_path, phase_classifier_path):\n",
    "        print(\"\\n--- 통합 파이프라인 초기화 ---\")\n",
    "        # 1. Mask R-CNN 모델 로드 (추론 모드)\n",
    "        self.mrcnn_model = modellib.MaskRCNN(mode=\"inference\", config=mrcnn_config,\n",
    "                                             model_dir=os.path.dirname(mrcnn_weights_path))\n",
    "        self.mrcnn_model.load_weights(mrcnn_weights_path, by_name=True)\n",
    "        print(\"Mask R-CNN 가중치 로드 완료.\")\n",
    "\n",
    "        # 2. 특징 추출기 모델 정의\n",
    "        self.feature_extractor = Model(inputs=self.mrcnn_model.keras_model.input,\n",
    "                                       outputs=self.mrcnn_model.keras_model.get_layer('res5c_out').output)\n",
    "        print(\"특징 추출기 모델 정의 완료.\")\n",
    "        \n",
    "        # 3. 단계 분류기 모델 로드\n",
    "        from keras.models import load_model\n",
    "        self.phase_classifier = load_model(phase_classifier_path)\n",
    "        print(\"단계 분류기 모델 로드 완료.\")\n",
    "        \n",
    "        self.mrcnn_config = mrcnn_config\n",
    "\n",
    "    def predict(self, image):\n",
    "        \"\"\"이미지 한 장에 대해 도구 인식과 단계 예측을 모두 수행합니다.\"\"\"\n",
    "        # 도구 인식 (Mask R-CNN)\n",
    "        tool_results = self.mrcnn_model.detect([image], verbose=0)[0]\n",
    "        \n",
    "        # 단계 예측을 위한 특징 추출\n",
    "        molded_image, _, _, _, _ = utils.mold_inputs([image], self.mrcnn_config)\n",
    "        feature_map = self.feature_extractor.predict(molded_image)\n",
    "        feature_vector = np.mean(feature_map, axis=(1, 2))\n",
    "        \n",
    "        # 단계 예측 (Phase Classifier)\n",
    "        phase_prediction_probs = self.phase_classifier.predict(feature_vector)[0]\n",
    "        predicted_phase_id = np.argmax(phase_prediction_probs)\n",
    "        \n",
    "        return tool_results, predicted_phase_id, phase_prediction_probs\n",
    "\n",
    "# --- 4. 메인 실행 로직 ---\n",
    "def main():\n",
    "    # --- 경로 설정 ---\n",
    "    ROOT_DIR = Path.cwd()\n",
    "    MODEL_DIR = ROOT_DIR / \"logs\"\n",
    "    COCO_MODEL_PATH = ROOT_DIR / \"mask_rcnn_coco.h5\"\n",
    "    PHASE_CLASSIFIER_PATH = ROOT_DIR / \"phase_classifier.h5\"\n",
    "\n",
    "    base_data_path = ROOT_DIR.parent / \"dataset/dataset001/179.6개암 최소침습수술 AI학습데이터/01.데이터/1.Training/\"\n",
    "    phase_directory_path =ROOT_DIR / \"output_phase_labeling5/\"\n",
    "    \n",
    "    # --- 데이터셋 준비 ---\n",
    "    parser = SurgicalDatasetParser(str(base_data_path), str(phase_directory_path))\n",
    "    \n",
    "    dataset_items = list(parser.prepare_dataset_for_keras())\n",
    "    if not dataset_items: \n",
    "        print(\"오류: 처리된 데이터가 없어 프로그램을 종료합니다\")\n",
    "        return\n",
    "\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(dataset_items)\n",
    "    val_split_idx = int(len(dataset_items) * 0.9)\n",
    "    train_items = dataset_items[:val_split_idx]\n",
    "    val_items = dataset_items[val_split_idx:]\n",
    "\n",
    "    dataset_train = SurgicalDataset(); dataset_train.load_surgical_data(parser, train_items, \"train\"); dataset_train.prepare()\n",
    "    dataset_val = SurgicalDataset(); dataset_val.load_surgical_data(parser, val_items, \"val\"); dataset_val.prepare()\n",
    "\n",
    "    # --- 설정 ---\n",
    "    config = SurgicalConfig()\n",
    "    config.NUM_CLASSES = 1 + len(parser.tool_categories)\n",
    "    config.NUM_PHASES = parser.num_phases\n",
    "    config.STEPS_PER_EPOCH = len(train_items) // config.IMAGES_PER_GPU\n",
    "    config.VALIDATION_STEPS = len(val_items) // config.IMAGES_PER_GPU if val_items else 1\n",
    "    #config.display()\n",
    "    \n",
    "    config.IMAGE_META_SIZE = 1 + 3 + 3 + 4 + 1 + config.NUM_CLASSES\n",
    "    \n",
    "    print(\"\\n [수정완료]동적으로IMAGE_META_SIZE를 재계산 했습니다. \")\n",
    "    config.display()\n",
    "    \n",
    "    # --- 1단계: Mask R-CNN 학습 ---\n",
    "    # 이미 학습된 가중치가 있다면 이 단계를 건너뛸 수 있습니다.\n",
    "    mrcnn_weights_path = train_mask_rcnn(config, dataset_train, dataset_val, str(MODEL_DIR),str(COCO_MODEL_PATH))\n",
    "    # mrcnn_weights_path = \"/path/to/your/trained/weights.h5\" # 직접 경로 지정도 가능\n",
    "\n",
    "    # --- 2단계: 특징 추출 및 분류기 학습 ---\n",
    "    class InferenceConfig(SurgicalConfig):\n",
    "        GPU_COUNT = 1\n",
    "        IMAGES_PER_GPU = 1\n",
    "    inference_config = InferenceConfig()\n",
    "    inference_config.NUM_CLASSES = config.NUM_CLASSES\n",
    "    inference_config.NUM_PHASES = config.NUM_PHASES\n",
    "    \n",
    "    X_train, y_train = extract_features(inference_config, dataset_train, mrcnn_weights_path)\n",
    "    X_val, y_val = extract_features(inference_config, dataset_val, mrcnn_weights_path)\n",
    "    \n",
    "    train_phase_classifier(X_train, y_train, X_val, y_val, parser.num_phases,str(PHASE_CLASSIFIER_PATH))\n",
    "\n",
    "    # --- 3단계: 통합 파이프라인으로 추론 테스트 ---\n",
    "    pipeline = SurgicalPipeline(inference_config, mrcnn_weights_path, str(PHASE_CLASSIFIER_PATH))\n",
    "    \n",
    "    # 검증 데이터셋에서 임의의 이미지로 테스트\n",
    "    if val_items:\n",
    "        image_id = np.random.choice(dataset_val.image_ids)\n",
    "        image = dataset_val.load_image(image_id)\n",
    "        true_phase_id = dataset_val.load_phase_label(image_id)\n",
    "        \n",
    "        tool_results, predicted_phase_id, phase_probs = pipeline.predict(image)\n",
    "        \n",
    "        predicted_phase_name = parser.idx_to_phase.get(predicted_phase_id, \"N/A\")\n",
    "        true_phase_name = parser.idx_to_phase.get(true_phase_id, \"N/A\")\n",
    "        \n",
    "        print(\"\\n--- 최종 추론 결과 ---\")\n",
    "        print(f\"이미지: {dataset_val.image_reference(image_id)}\")\n",
    "        print(f\"실제 수술 단계: {true_phase_name}\")\n",
    "        print(f\"예측된 수술 단계: {predicted_phase_name} (신뢰도: {phase_probs[predicted_phase_id]:.2f})\")\n",
    "        \n",
    "        # 도구 인식 결과 시각화\n",
    "        visualize.display_instances(image, tool_results['rois'], tool_results['masks'],\n",
    "                                    tool_results['class_ids'], dataset_val.class_names,\n",
    "                                    tool_results['scores'],\n",
    "                                    title=f\"Predicted Phase: {predicted_phase_name}\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발견된 수술 도구 카테고리: 26개\n",
      " ID 1: Bowel Graspers (straight) (AESCULAP) (GRSL-BWAE)\n",
      " ID 2: Dissector (Artisential) (DSTL-ATUK)\n",
      " ID 3: Dissector (kelly) (AESCULAP) (DSTL-KLAE)\n",
      " ID 4: Drain (JPCL-UCUK)\n",
      " ID 5: Endobulldog Clamp (CLML-BDUK)\n",
      " ID 6: Gauze (GAUL-UCUK)\n",
      " ID 7: Gauze Ball (GAUL-BAUK)\n",
      " ID 8: Graspers (curved) (KARL STORZ) (GRSL-C2KS)\n",
      " ID 9: Graspers (curved) (KARL STORZ) (GRSL-CIKS)\n",
      " ID 10: Graspers (duckbill) (GRSL-DBUK)\n",
      " ID 11: Graspers (straight) (KARL STORZ) (GRSL-STKS)\n",
      " ID 12: Harmonic Scalpel (ETHICON) (HMSL-UCET)\n",
      " ID 13: Irrigator (IRGL-UCUK)\n",
      " ID 14: Ligasure (COVIDIEN) (LGSL-MACV)\n",
      " ID 15: Linear Stapler (EGSL-UCUK)\n",
      " ID 16: Linear Stapler (ETHICON) (STPL-UCET)\n",
      " ID 17: Liver retractor (LVRL-UCUK)\n",
      " ID 18: Needle Holder (AESCULAP) (NDHL-UCAE)\n",
      " ID 19: Obturator (OBTL-UCUK)\n",
      " ID 20: Polymer Clip Applier (CLAL-UCUK)\n",
      " ID 21: Spatula Suction (ETHICON) (SPSL-UCET)\n",
      " ID 22: Specimen Retrieval Bag (RTBL-UCUK)\n",
      " ID 23: Suction Irrigator (ETHICON) (SIRL-UCET)\n",
      " ID 24: Suction Irrigator (RDSL-UCUK)\n",
      " ID 25: Suction Irrigator (SIRL-UCUK)\n",
      " ID 26: Trocar (TRCL-UCUK)\n",
      "발견된 수술 단계: 13개 - ['Anastomosis', 'Closure', 'Duodenal transection', 'Left greater curvature dissection', 'Lesser curvature preparation', 'Preparation', 'Proximal stomach transection', 'Right greater curvature dissection', 'Right lesser curvature dissection', 'Right paracardial dissection', 'Stomach specimen removal', 'Suprapancreatic dissection', 'Unknown']\n",
      "데이터셋 준비 시작 :  하위 폴더에서 모든 xmL 파일을 찾습니다.\n",
      "총 31086개의 XML 파일을 찾았습니다.\n",
      "진행 중 : 31086 / 31086 항목 처리 완료\n",
      "==================================================\n",
      "총 9767개 학습/검증용 아이템 준비 완료\n",
      "==================================================\n",
      "'train' 데이터셋에 8790개 이미지를 로드했습니다.\n",
      "'val' 데이터셋에 977개 이미지를 로드했습니다.\n",
      "\n",
      " [수정완료]동적으로IMAGE_META_SIZE를 재계산 했습니다. \n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                39\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           surgical_tool_phase\n",
      "NUM_CLASSES                    27\n",
      "NUM_PHASES                     13\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                4395\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               488\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "\n",
      "--- 1단계: Mask R-CNN (특징 추출기) 학습 시작 ---\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "헤드 레이어 학습...\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /tf/nasw/logs/surgical_tool_phase20250611T0427/mask_rcnn_surgical_tool_phase_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1093/4395 [======>.......................] - ETA: 18:56:01 - loss: 1.3147 - rpn_class_loss: 0.0075 - rpn_bbox_loss: 0.3657 - mrcnn_class_loss: 0.1696 - mrcnn_bbox_loss: 0.3335 - mrcnn_mask_loss: 0.4383"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-7:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-8:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-11:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "Process ForkPoolWorker-3:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Process ForkPoolWorker-10:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-7f82d780937b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# --- 1단계: Mask R-CNN 학습 ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# 이미 학습된 가중치가 있다면 이 단계를 건너뛸 수 있습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0mmrcnn_weights_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_mask_rcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOCO_MODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;31m# mrcnn_weights_path = \"/path/to/your/trained/weights.h5\" # 직접 경로 지정도 가능\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-7f82d780937b>\u001b[0m in \u001b[0;36mtrain_mask_rcnn\u001b[0;34m(config, train_dataset, val_dataset, model_dir, coco_model_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 예시: 실제로는 더 많은 에폭 필요\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 layers='heads')\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"모든 레이어 미세 조정 학습...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation)\u001b[0m\n\u001b[1;32m   2350\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2352\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2353\u001b[0m         )\n\u001b[1;32m   2354\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/mrcnn\n",
      "/usr/local/lib/python3.6/dist-packages/mrcnn/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import mrcnn\n",
    "import os\n",
    "print(os.path.dirname(mrcnn.__file__))\n",
    "print(mrcnn.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/mrcnn\n"
     ]
    }
   ],
   "source": [
    "cd /usr/local/lib/python3.6/dist-packages/mrcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발견된 수술 도구 카테고리: 26개\n",
      " ID 1: Bowel Graspers (straight) (AESCULAP) (GRSL-BWAE)\n",
      " ID 2: Dissector (Artisential) (DSTL-ATUK)\n",
      " ID 3: Dissector (kelly) (AESCULAP) (DSTL-KLAE)\n",
      " ID 4: Drain (JPCL-UCUK)\n",
      " ID 5: Endobulldog Clamp (CLML-BDUK)\n",
      " ID 6: Gauze (GAUL-UCUK)\n",
      " ID 7: Gauze Ball (GAUL-BAUK)\n",
      " ID 8: Graspers (curved) (KARL STORZ) (GRSL-C2KS)\n",
      " ID 9: Graspers (curved) (KARL STORZ) (GRSL-CIKS)\n",
      " ID 10: Graspers (duckbill) (GRSL-DBUK)\n",
      " ID 11: Graspers (straight) (KARL STORZ) (GRSL-STKS)\n",
      " ID 12: Harmonic Scalpel (ETHICON) (HMSL-UCET)\n",
      " ID 13: Irrigator (IRGL-UCUK)\n",
      " ID 14: Ligasure (COVIDIEN) (LGSL-MACV)\n",
      " ID 15: Linear Stapler (EGSL-UCUK)\n",
      " ID 16: Linear Stapler (ETHICON) (STPL-UCET)\n",
      " ID 17: Liver retractor (LVRL-UCUK)\n",
      " ID 18: Needle Holder (AESCULAP) (NDHL-UCAE)\n",
      " ID 19: Obturator (OBTL-UCUK)\n",
      " ID 20: Polymer Clip Applier (CLAL-UCUK)\n",
      " ID 21: Spatula Suction (ETHICON) (SPSL-UCET)\n",
      " ID 22: Specimen Retrieval Bag (RTBL-UCUK)\n",
      " ID 23: Suction Irrigator (ETHICON) (SIRL-UCET)\n",
      " ID 24: Suction Irrigator (RDSL-UCUK)\n",
      " ID 25: Suction Irrigator (SIRL-UCUK)\n",
      " ID 26: Trocar (TRCL-UCUK)\n",
      "발견된 수술 단계: 13개 - ['Anastomosis', 'Closure', 'Duodenal transection', 'Left greater curvature dissection', 'Lesser curvature preparation', 'Preparation', 'Proximal stomach transection', 'Right greater curvature dissection', 'Right lesser curvature dissection', 'Right paracardial dissection', 'Stomach specimen removal', 'Suprapancreatic dissection', 'Unknown']\n",
      "전체 항목 수 : 26개\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXMLSyntaxError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-fcda8efc6591>\u001b[0m in \u001b[0;36m_parse_xml_annotation\u001b[0;34m(self, xml_file)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/lxml/etree.pyx\u001b[0m in \u001b[0;36mlxml.etree.parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseDocument\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseDocumentFromURL\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._parseDocFromFile\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._BaseParser._parseDocFromFile\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._ParserContext._handleParseResultDoc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._handleParseResult\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._raiseParseError\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mXMLSyntaxError\u001b[0m: Start tag expected, '<' not found, line 1, column 1 (GGHB_DC16_LWK0_LDG0_0011_0021898.json, line 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-fcda8efc6591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-fcda8efc6591>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;31m# --- 데이터셋 준비 ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSurgicalDatasetParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase_directory_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0mdataset_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_dataset_for_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdataset_items\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-fcda8efc6591>\u001b[0m in \u001b[0;36mprepare_dataset_for_keras\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtool_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxml_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtool_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_xml_annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mannotation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'objects'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mimage_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_matching_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-fcda8efc6591>\u001b[0m in \u001b[0;36m_parse_xml_annotation\u001b[0;34m(self, xml_file)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_parse_xml_annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxml_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mobjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Keras/TF 버전으로 수정: 필요한 라이브러리 임포트\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Keras 및 TensorFlow 관련 라이브러리\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# lxml 임포트\n",
    "try:\n",
    "    import lxml.etree as etree\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as etree\n",
    "    print(\"경고: lxml 라이브러리를 찾을 수 없어 표준 xml.etree.ElementTree를 사용합니다.\")\n",
    "\n",
    "# Matterport Mask R-CNN 라이브러리 임포트\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "\n",
    "# --- 1. 데이터 파싱 및 설정 클래스 (이전과 거의 동일) ---\n",
    "# 이전 답변에서 제공된 SurgicalDatasetParser, SurgicalDataset, SurgicalConfig 클래스를 그대로 사용합니다.\n",
    "# 생략된 코드는 첨부된 파일 [1] 또는 이전 답변을 참고해주세요.\n",
    "class SurgicalDatasetParser:\n",
    "    # ... 이전 코드와 동일 ... [1]\n",
    "    def __init__(self, base_path, phase_directory_path):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.label_path = self.base_path/\"라벨링데이터\"/\"클래스1.(수술도구 이미지)\"/\"01.원위부위절제술\"\n",
    "        self.image_path = self.base_path/\"원천데이터\"/\"클래스1.(수술도구 이미지)\"/\"01.원위부위절제술\"\n",
    "        self.tool_categories = self._discover_tool_categories()\n",
    "        self.class_to_idx = {cat['name']: cat['id'] for cat in self.tool_categories}\n",
    "        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}\n",
    "        print(f\"발견된 수술 도구 카테고리: {len(self.tool_categories)}개\")\n",
    "        for cat in self.tool_categories: print(f\" ID {cat['id']}: {cat['name']}\")\n",
    "        self.image_stem_to_phase_map = self._load_phase_data(phase_directory_path)\n",
    "        if self.image_stem_to_phase_map:\n",
    "            self.phases = sorted(list(set(self.image_stem_to_phase_map.values())))\n",
    "            self.phase_to_idx = {name: i for i, name in enumerate(self.phases)}\n",
    "            self.idx_to_phase = {i: name for i, name in enumerate(self.phases)}\n",
    "            self.num_phases = len(self.phases)\n",
    "            print(f\"발견된 수술 단계: {self.num_phases}개 - {self.phases}\")\n",
    "        else:\n",
    "            self.phases, self.phase_to_idx, self.idx_to_phase, self.num_phases = [], {}, {}, 0\n",
    "    def _discover_tool_categories(self):\n",
    "        categories = []\n",
    "        if self.label_path.exists():\n",
    "            tool_folders = sorted([f for f in self.label_path.iterdir() if f.is_dir()])\n",
    "            categories = [{\"id\": idx + 1, \"name\": folder.name} for idx, folder in enumerate(tool_folders)]\n",
    "        return categories\n",
    "    def _load_phase_data(self, phase_directory_path):\n",
    "        image_stem_to_phase = {}\n",
    "        if not phase_directory_path: return image_stem_to_phase\n",
    "        phase_dir = Path(phase_directory_path)\n",
    "        if not phase_dir.is_dir(): return image_stem_to_phase\n",
    "        for json_file_path in phase_dir.glob(\"*.json\"):\n",
    "            try:\n",
    "                with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                for entry in data:\n",
    "                    if isinstance(entry, dict) and \"filename\" in entry and \"phase\" in entry:\n",
    "                        image_stem_to_phase[Path(entry[\"filename\"]).stem] = entry[\"phase\"]\n",
    "            except Exception: continue\n",
    "        return image_stem_to_phase\n",
    "    def prepare_dataset_for_keras(self):\n",
    "        dataset_items = []\n",
    "        total_items = sum(1 for tool_dir in self.label_path.iterdir() if tool_dir.is_dir())\n",
    "        processed_items = 0\n",
    "        print(f\"전체 항목 수 : {total_items}개\")\n",
    "        for tool_dir in self.label_path.iterdir():\n",
    "            if not tool_dir.is_dir(): continue\n",
    "            for xml_file in tool_dir.glob(\"*.json\"):\n",
    "                annotation = self._parse_xml_annotation(xml_file)\n",
    "                if not annotation or not annotation.get('objects'): continue\n",
    "                image_file = self._find_matching_image(xml_file.stem, tool_dir.name)\n",
    "                if not image_file: continue\n",
    "                phase_label = self.image_stem_to_phase_map.get(xml_file.stem)\n",
    "                if phase_label is None or phase_label not in self.phase_to_idx: continue\n",
    "                dataset_items.append({\n",
    "                    'image_path': str(image_file),\n",
    "                    'width': annotation['size']['width'], 'height': annotation['size']['height'],\n",
    "                    'objects': annotation['objects'],\n",
    "                    'phase_id': self.phase_to_idx[phase_label]\n",
    "                })\n",
    "                processed_items += 1\n",
    "                print(f\"진행 중 : {processed_items} / {total_items} 항목 처리 완료\")\n",
    "                                               \n",
    "        print(f\"총 {len(dataset_items)}개 학습/검증용 아이템 준비 완료\")\n",
    "        return dataset_items\n",
    "                                               \n",
    "    def _parse_xml_annotation(self, xml_file):\n",
    "        try:\n",
    "            tree = etree.parse(str(xml_file))\n",
    "            size = tree.find('size')\n",
    "            objects = []\n",
    "            for obj in tree.findall('object'):\n",
    "                class_name = obj.find('name').text\n",
    "                if class_name not in self.class_to_idx: continue\n",
    "                points_elem = obj.find('points')\n",
    "                if points_elem is not None:\n",
    "                    points = [{'x': float(x.text), 'y': float(y.text)} for x, y in zip(points_elem.findall('x'), points_elem.findall('y'))]\n",
    "                    if points: objects.append({'name': class_name, 'points': points})\n",
    "            return {'size': {'width': int(size.find('width').text), 'height': int(size.find('height').text)}, 'objects': objects}\n",
    "        except Exception: return None\n",
    "    def _find_matching_image(self, stem, folder):\n",
    "        for ext in ['.png', '.jpg', '.jpeg']:\n",
    "            img_path = self.image_path / folder / (stem + ext)\n",
    "            if img_path.exists():\n",
    "                return img_path\n",
    "        return None\n",
    "class SurgicalDataset(utils.Dataset):\n",
    "    # ... 이전 코드와 동일 ... [1]\n",
    "    def load_surgical_data(self, parser, dataset_items, dataset_type):\n",
    "        self.parser = parser\n",
    "        for cat in self.parser.tool_categories: self.add_class(\"surgical_tool\", cat['id'], cat['name'])\n",
    "        for i, item in enumerate(dataset_items):\n",
    "            self.add_image(\"surgical_tool\", image_id=i, path=item['image_path'], width=item['width'], height=item['height'], polygons=item['objects'], phase_id=item['phase_id'])\n",
    "        print(f\"'{dataset_type}' 데이터셋에 {len(dataset_items)}개 이미지를 로드했습니다.\")\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        masks, class_ids = [], []\n",
    "        for obj in info[\"polygons\"]:\n",
    "            points = np.array([[p['x'], p['y']] for p in obj['points']], dtype=np.int32)\n",
    "            mask = np.zeros([info[\"height\"], info[\"width\"]], dtype=np.uint8)\n",
    "            cv2.fillPoly(mask, [points], 1)\n",
    "            masks.append(mask)\n",
    "            class_ids.append(self.parser.class_to_idx[obj['name']])\n",
    "        return (np.stack(masks, axis=-1).astype(bool), np.array(class_ids, dtype=np.int32)) if masks else super(self.__class__, self).load_mask(image_id)\n",
    "    def image_reference(self, image_id): return self.image_info[image_id][\"path\"]\n",
    "    def load_phase_label(self, image_id): return self.image_info[image_id]['phase_id']\n",
    "\n",
    "class SurgicalConfig(Config):\n",
    "    # ... 이전 코드와 동일 ... [1]\n",
    "    NAME = \"surgical_tool_phase\"\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 2\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    LEARNING_RATE = 0.001\n",
    "\n",
    "# --- 2. 모델 학습 및 특징 추출, 분류기 학습 함수 정의 ---\n",
    "\n",
    "def train_mask_rcnn(config, train_dataset, val_dataset, model_dir, coco_model_path):\n",
    "    \"\"\"1단계: Mask R-CNN 모델을 학습시킵니다.\"\"\"\n",
    "    print(\"\\n--- 1단계: Mask R-CNN (특징 추출기) 학습 시작 ---\")\n",
    "    model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=model_dir)\n",
    "    \n",
    "    # 전이 학습을 위해 COCO 가중치 로드 (최종 레이어 제외)\n",
    "    model.load_weights(coco_model_path, by_name=True, exclude=[\n",
    "        \"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "    print(\"헤드 레이어 학습...\")\n",
    "    model.train(train_dataset, val_dataset,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=5, # 예시: 실제로는 더 많은 에폭 필요\n",
    "                layers='heads')\n",
    "    \n",
    "    print(\"모든 레이어 미세 조정 학습...\")\n",
    "    model.train(train_dataset, val_dataset,\n",
    "                learning_rate=config.LEARNING_RATE / 10,\n",
    "                epochs=10, # 예시: 실제로는 더 많은 에폭 필요\n",
    "                layers='all')\n",
    "    \n",
    "    print(\"Mask R-CNN 학습 완료.\")\n",
    "    return model.find_last() # 학습된 최신 가중치 경로 반환\n",
    "\n",
    "def extract_features(inference_config, dataset, model_path):\n",
    "    \"\"\"학습된 Mask R-CNN을 사용하여 특징 벡터를 추출합니다.\"\"\"\n",
    "    print(\"\\n--- 2단계 (준비): 이미지 특징 벡터 추출 시작 ---\")\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", config=inference_config, model_dir=os.path.dirname(model_path))\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "\n",
    "    # ResNet 백본의 마지막 출력을 특징으로 사용하기 위한 새로운 모델 정의\n",
    "    # 'res5c_out'은 ResNet-101의 마지막 컨볼루션 블록의 출력 레이어 이름입니다.\n",
    "    feature_extractor = Model(inputs=model.keras_model.input,\n",
    "                              outputs=model.keras_model.get_layer('res5c_out').output)\n",
    "    \n",
    "    features = []\n",
    "    phase_labels = []\n",
    "    \n",
    "    for image_id in dataset.image_ids:\n",
    "        image = dataset.load_image(image_id)\n",
    "        # 이미지를 모델 입력에 맞게 리사이즈 및 정규화\n",
    "        molded_image, _, _, _, _ = utils.mold_inputs([image], inference_config)\n",
    "        # 특징 추출\n",
    "        feature_map = feature_extractor.predict(molded_image)\n",
    "        # 특징 맵을 1D 벡터로 변환 (Global Average Pooling)\n",
    "        vector = np.mean(feature_map, axis=(1, 2)).squeeze()\n",
    "        \n",
    "        features.append(vector)\n",
    "        phase_labels.append(dataset.load_phase_label(image_id))\n",
    "        \n",
    "        if (image_id + 1) % 100 == 0:\n",
    "            print(f\"{image_id + 1} / {len(dataset.image_ids)} 이미지 처리 완료\")\n",
    "\n",
    "    print(f\"총 {len(features)}개의 특징 벡터 추출 완료.\")\n",
    "    return np.array(features), np.array(phase_labels)\n",
    "\n",
    "def train_phase_classifier(X_train, y_train, X_val, y_val, num_phases, model_save_path):\n",
    "    #\"\"\"추출된 특징 벡터로 수술 단계 분류기를 학습합니다.\"\"\"\n",
    "    print(\"\\n--- 2단계: 수술 단계 분류기 학습 시작 ---\")\n",
    "    \n",
    "    # 라벨을 원-핫 인코딩으로 변환\n",
    "    y_train_cat = to_categorical(y_train, num_classes=num_phases)\n",
    "    y_val_cat = to_categorical(y_val, num_classes=num_phases)\n",
    "    \n",
    "    input_shape = (X_train.shape[1],)\n",
    "    \n",
    "    # 간단한 MLP 모델 정의\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    x = Dense(512, activation='relu')(input_tensor)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_tensor = Dense(num_phases, activation='softmax')(x)\n",
    "    \n",
    "    classifier = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    \n",
    "    classifier.compile(optimizer=Adam(lr=0.0001),\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "    \n",
    "    print(classifier.summary())\n",
    "    \n",
    "    classifier.fit(X_train, y_train_cat,\n",
    "                   validation_data=(X_val, y_val_cat),\n",
    "                   epochs=30, # 예시: 실제로는 더 많은 에폭 필요\n",
    "                   batch_size=32)\n",
    "    \n",
    "    classifier.save(model_save_path)\n",
    "    print(f\"단계 분류기 모델 저장 완료: {model_save_path}\")\n",
    "    return classifier\n",
    "\n",
    "# --- 3. 통합 추론 파이프라인 클래스 ---\n",
    "\n",
    "class SurgicalPipeline:\n",
    "    \"\"\"Mask R-CNN과 단계 분류기를 통합하여 추론을 수행하는 클래스\"\"\"\n",
    "    def __init__(self, mrcnn_config, mrcnn_weights_path, phase_classifier_path):\n",
    "        print(\"\\n--- 통합 파이프라인 초기화 ---\")\n",
    "        # 1. Mask R-CNN 모델 로드 (추론 모드)\n",
    "        self.mrcnn_model = modellib.MaskRCNN(mode=\"inference\", config=mrcnn_config,\n",
    "                                             model_dir=os.path.dirname(mrcnn_weights_path))\n",
    "        self.mrcnn_model.load_weights(mrcnn_weights_path, by_name=True)\n",
    "        print(\"Mask R-CNN 가중치 로드 완료.\")\n",
    "\n",
    "        # 2. 특징 추출기 모델 정의\n",
    "        self.feature_extractor = Model(inputs=self.mrcnn_model.keras_model.input,\n",
    "                                       outputs=self.mrcnn_model.keras_model.get_layer('res5c_out').output)\n",
    "        print(\"특징 추출기 모델 정의 완료.\")\n",
    "        \n",
    "        # 3. 단계 분류기 모델 로드\n",
    "        from keras.models import load_model\n",
    "        self.phase_classifier = load_model(phase_classifier_path)\n",
    "        print(\"단계 분류기 모델 로드 완료.\")\n",
    "        \n",
    "        self.mrcnn_config = mrcnn_config\n",
    "\n",
    "    def predict(self, image):\n",
    "        \"\"\"이미지 한 장에 대해 도구 인식과 단계 예측을 모두 수행합니다.\"\"\"\n",
    "        # 도구 인식 (Mask R-CNN)\n",
    "        tool_results = self.mrcnn_model.detect([image], verbose=0)[0]\n",
    "        \n",
    "        # 단계 예측을 위한 특징 추출\n",
    "        molded_image, _, _, _, _ = utils.mold_inputs([image], self.mrcnn_config)\n",
    "        feature_map = self.feature_extractor.predict(molded_image)\n",
    "        feature_vector = np.mean(feature_map, axis=(1, 2))\n",
    "        \n",
    "        # 단계 예측 (Phase Classifier)\n",
    "        phase_prediction_probs = self.phase_classifier.predict(feature_vector)[0]\n",
    "        predicted_phase_id = np.argmax(phase_prediction_probs)\n",
    "        \n",
    "        return tool_results, predicted_phase_id, phase_prediction_probs\n",
    "\n",
    "# --- 4. 메인 실행 로직 ---\n",
    "def main():\n",
    "    # --- 경로 설정 ---\n",
    "    ROOT_DIR = Path.cwd()\n",
    "    MODEL_DIR = ROOT_DIR / \"logs\"\n",
    "    COCO_MODEL_PATH = ROOT_DIR / \"mask_rcnn_coco.h5\"\n",
    "    PHASE_CLASSIFIER_PATH = ROOT_DIR / \"phase_classifier.h5\"\n",
    "\n",
    "    base_data_path = Path(\"../dataset/dataset001/179.6개암 최소침습수술 AI학습데이터/01.데이터/1.Training/\")\n",
    "    phase_directory_path = Path(\"./output_phase_labeling5/\")\n",
    "    \n",
    "    # --- 데이터셋 준비 ---\n",
    "    parser = SurgicalDatasetParser(base_data_path, phase_directory_path)\n",
    "    dataset_items = parser.prepare_dataset_for_keras()\n",
    "    if not dataset_items: return\n",
    "\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(dataset_items)\n",
    "    val_split_idx = int(len(dataset_items) * 0.9)\n",
    "    train_items = dataset_items[:val_split_idx]\n",
    "    val_items = dataset_items[val_split_idx:]\n",
    "\n",
    "    dataset_train = SurgicalDataset(); dataset_train.load_surgical_data(parser, train_items, \"train\"); dataset_train.prepare()\n",
    "    dataset_val = SurgicalDataset(); dataset_val.load_surgical_data(parser, val_items, \"val\"); dataset_val.prepare()\n",
    "\n",
    "    # --- 설정 ---\n",
    "    config = SurgicalConfig()\n",
    "    config.NUM_CLASSES = 1 + len(parser.tool_categories)\n",
    "    config.NUM_PHASES = parser.num_phases\n",
    "    config.STEPS_PER_EPOCH = len(train_items) // config.IMAGES_PER_GPU\n",
    "    config.VALIDATION_STEPS = len(val_items) // config.IMAGES_PER_GPU if val_items else 1\n",
    "    config.display()\n",
    "    \n",
    "    # --- 1단계: Mask R-CNN 학습 ---\n",
    "    # 이미 학습된 가중치가 있다면 이 단계를 건너뛸 수 있습니다.\n",
    "    mrcnn_weights_path = train_mask_rcnn(config, dataset_train, dataset_val, MODEL_DIR, COCO_MODEL_PATH)\n",
    "    # mrcnn_weights_path = \"/path/to/your/trained/weights.h5\" # 직접 경로 지정도 가능\n",
    "\n",
    "    # --- 2단계: 특징 추출 및 분류기 학습 ---\n",
    "    class InferenceConfig(SurgicalConfig):\n",
    "        GPU_COUNT = 1\n",
    "        IMAGES_PER_GPU = 1\n",
    "    inference_config = InferenceConfig()\n",
    "    inference_config.NUM_CLASSES = config.NUM_CLASSES\n",
    "    inference_config.NUM_PHASES = config.NUM_PHASES\n",
    "    \n",
    "    X_train, y_train = extract_features(inference_config, dataset_train, mrcnn_weights_path)\n",
    "    X_val, y_val = extract_features(inference_config, dataset_val, mrcnn_weights_path)\n",
    "    \n",
    "    train_phase_classifier(X_train, y_train, X_val, y_val, parser.num_phases, PHASE_CLASSIFIER_PATH)\n",
    "\n",
    "    # --- 3단계: 통합 파이프라인으로 추론 테스트 ---\n",
    "    pipeline = SurgicalPipeline(inference_config, mrcnn_weights_path, PHASE_CLASSIFIER_PATH)\n",
    "    \n",
    "    # 검증 데이터셋에서 임의의 이미지로 테스트\n",
    "    if val_items:\n",
    "        image_id = np.random.choice(dataset_val.image_ids)\n",
    "        image = dataset_val.load_image(image_id)\n",
    "        true_phase_id = dataset_val.load_phase_label(image_id)\n",
    "        \n",
    "        tool_results, predicted_phase_id, phase_probs = pipeline.predict(image)\n",
    "        \n",
    "        predicted_phase_name = parser.idx_to_phase.get(predicted_phase_id, \"N/A\")\n",
    "        true_phase_name = parser.idx_to_phase.get(true_phase_id, \"N/A\")\n",
    "        \n",
    "        print(\"\\n--- 최종 추론 결과 ---\")\n",
    "        print(f\"이미지: {dataset_val.image_reference(image_id)}\")\n",
    "        print(f\"실제 수술 단계: {true_phase_name}\")\n",
    "        print(f\"예측된 수술 단계: {predicted_phase_name} (신뢰도: {phase_probs[predicted_phase_id]:.2f})\")\n",
    "        \n",
    "        # 도구 인식 결과 시각화\n",
    "        visualize.display_instances(image, tool_results['rois'], tool_results['masks'],\n",
    "                                    tool_results['class_ids'], dataset_val.class_names,\n",
    "                                    tool_results['scores'],\n",
    "                                    title=f\"Predicted Phase: {predicted_phase_name}\")\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.client'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0ca82b29604d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.client'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute '_version_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c1bf3b5133da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_version_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_built_with_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_gpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuda_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_cuda_compute_capability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute '_version_'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf._version_)\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                Version\n",
      "---------------------- -----------\n",
      "absl-py                1.4.0\n",
      "argon2-cffi            21.3.0\n",
      "argon2-cffi-bindings   21.2.0\n",
      "asn1crypto             0.24.0\n",
      "astor                  0.8.1\n",
      "async-generator        1.10\n",
      "attrs                  22.2.0\n",
      "backcall               0.2.0\n",
      "bleach                 4.1.0\n",
      "cached-property        1.5.2\n",
      "cffi                   1.15.1\n",
      "click                  8.0.4\n",
      "cryptography           2.1.4\n",
      "cycler                 0.11.0\n",
      "dataclasses            0.8\n",
      "decorator              4.4.2\n",
      "defusedxml             0.7.1\n",
      "entrypoints            0.4\n",
      "Flask                  2.0.3\n",
      "gast                   0.6.0\n",
      "google-pasta           0.2.0\n",
      "grpcio                 1.48.2\n",
      "h5py                   2.10.0\n",
      "idna                   2.6\n",
      "imageio                2.15.0\n",
      "importlib-metadata     4.8.3\n",
      "importlib-resources    5.4.0\n",
      "intel-cmplr-lib-ur     2024.2.1\n",
      "intel-openmp           2024.2.1\n",
      "ipykernel              5.5.6\n",
      "ipython                7.16.3\n",
      "ipython-genutils       0.2.0\n",
      "itsdangerous           2.0.1\n",
      "jedi                   0.17.2\n",
      "Jinja2                 3.0.3\n",
      "joblib                 1.1.1\n",
      "jsonschema             3.2.0\n",
      "jupyter-client         7.1.2\n",
      "jupyter-core           4.9.2\n",
      "jupyterlab-pygments    0.1.2\n",
      "Keras                  2.2.4\n",
      "Keras-Applications     1.0.8\n",
      "Keras-Preprocessing    1.1.2\n",
      "keyring                10.6.0\n",
      "keyrings.alt           3.0\n",
      "kiwisolver             1.3.1\n",
      "lxml                   5.4.0\n",
      "Markdown               3.3.7\n",
      "MarkupSafe             2.0.1\n",
      "matplotlib             3.3.4\n",
      "mistune                0.8.4\n",
      "mkl                    2024.2.2\n",
      "mock                   5.2.0\n",
      "mrcnn                  0.2\n",
      "nbclient               0.5.9\n",
      "nbconvert              6.0.7\n",
      "nbformat               5.1.3\n",
      "nest-asyncio           1.6.0\n",
      "networkx               2.5.1\n",
      "notebook               6.4.10\n",
      "numpy                  1.19.5\n",
      "opencv-python          4.5.4.60\n",
      "opencv-python-headless 4.5.4.60\n",
      "packaging              21.3\n",
      "pandas                 1.1.5\n",
      "pandocfilters          1.5.1\n",
      "parso                  0.7.1\n",
      "pexpect                4.9.0\n",
      "pickleshare            0.7.5\n",
      "Pillow                 8.4.0\n",
      "pip                    21.3.1\n",
      "prometheus-client      0.17.1\n",
      "prompt-toolkit         3.0.36\n",
      "protobuf               3.19.6\n",
      "ptyprocess             0.7.0\n",
      "pycparser              2.21\n",
      "pycrypto               2.6.1\n",
      "Pygments               2.14.0\n",
      "PyGObject              3.26.1\n",
      "pyparsing              3.1.4\n",
      "pyrsistent             0.18.0\n",
      "python-apt             1.6.4\n",
      "python-dateutil        2.9.0.post0\n",
      "pytz                   2025.2\n",
      "PyWavelets             1.1.1\n",
      "pyxdg                  0.25\n",
      "PyYAML                 6.0.1\n",
      "pyzmq                  25.1.2\n",
      "scikit-image           0.15.0\n",
      "scikit-learn           0.24.2\n",
      "scipy                  1.5.4\n",
      "seaborn                0.11.2\n",
      "SecretStorage          2.3.1\n",
      "Send2Trash             1.8.3\n",
      "setuptools             59.6.0\n",
      "six                    1.11.0\n",
      "tbb                    2021.13.1\n",
      "tensorboard            1.13.1\n",
      "tensorflow-estimator   1.13.0\n",
      "tensorflow-gpu         1.14.0\n",
      "termcolor              1.1.0\n",
      "terminado              0.12.1\n",
      "testpath               0.6.0\n",
      "threadpoolctl          3.1.0\n",
      "tifffile               2020.9.3\n",
      "torch                  1.10.1\n",
      "torchvision            0.11.2\n",
      "tornado                6.1\n",
      "tqdm                   4.64.1\n",
      "traitlets              4.3.3\n",
      "typing_extensions      4.1.1\n",
      "wcwidth                0.2.13\n",
      "webencodings           0.5.1\n",
      "Werkzeug               2.0.3\n",
      "wheel                  0.30.0\n",
      "wrapt                  1.16.0\n",
      "zipp                   3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{width:100%!important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<style>.container{width:100%!important;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 1.13.1\n",
      "Uninstalling tensorflow-1.13.1:\n",
      "  Successfully uninstalled tensorflow-1.13.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y tensorflow  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'compat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-46db242e42b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'compat'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "\n",
    "# 위 명령시 gpu 인식 못하고 CPU 만 인식 - tensor flow 와 tesnorflow-gpu 의 버전이 달라서 생기는 오류로 예상 \n",
    "# 위 오류 해결후 동작하면 잘 되길..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as k\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "k.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/lib/python36.zip',\n",
       " '/usr/lib/python3.6',\n",
       " '/usr/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/usr/local/lib/python3.6/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
       " '/root/.ipython']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc8c045f940>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',)': /simple/tensorflow/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc8c045fa20>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',)': /simple/tensorflow/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc8c045fbe0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',)': /simple/tensorflow/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc8c045fd30>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',)': /simple/tensorflow/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc8c045fe80>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',)': /simple/tensorflow/\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for tensorflow\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
